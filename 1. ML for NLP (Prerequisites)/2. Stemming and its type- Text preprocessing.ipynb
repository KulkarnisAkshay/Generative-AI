{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71837a0-f844-4d0f-8cb1-56132dcf0dd1",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b938a2-9e03-4333-8e29-25f9b5e71a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten = eat --> stem \n",
    "##                going,gone,goes = go --->stem\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c959074-0f3d-43c3-974b-f74bd96d4a69",
   "metadata": {},
   "source": [
    "#### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2016b0-d785-473a-b0fe-ca66b6e4fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b7bf162-f238-4069-a519-93c1e9089597",
   "metadata": {},
   "outputs": [],
   "source": [
    "prtal_stem=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79b3e719-a428-4c19-a97c-d7d4ce6949b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "eaten ---> eaten\n",
      "writing ---> write\n",
      "writes ---> write\n",
      "programming ---> program\n",
      "programs ---> program\n",
      "history ---> histori\n",
      "finally ---> final\n",
      "finalized ---> final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \" + prtal_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c9880-3d63-4173-8e6b-c9c96d3db79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## history ---> histori  =======> problem (dis.adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e1dcfdf-4357-4e06-92cd-0ee545b82038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congradul'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prtal_stem.stem('Congradulations')   #=====> problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c624cb9-6acc-4249-8eb6-450ce959aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prtal_stem.stem('sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbd782-8268-44e5-ab8f-aa0ced0d4f88",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4162b44d-0001-4958-81f7-cd43df686f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59be18d9-fd93-4d53-8dd5-1d47b350a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e414e4-504c-4f31-94b3-041a633d85c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8bdaca5-ef54-49d2-a55c-870a0a70d2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af52cf-f080-4a8c-8941-2eedad108be2",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7080bb5-32f6-4b53-b523-7d7d05dbe564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b5b40ae-494e-438f-a1da-1541aaf95c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stem = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989c6134-97ee-44e3-b829-0ddeec60dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "eaten ---> eaten\n",
      "writing ---> write\n",
      "writes ---> write\n",
      "programming ---> program\n",
      "programs ---> program\n",
      "history ---> histori\n",
      "finally ---> final\n",
      "finalized ---> final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\" ---> \" + snowball_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "780b5338-7e86-41ec-820c-3654f153c825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prtal_stem.stem(\"fairly\"),prtal_stem.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1df58bd0-1227-48d8-b937-c45c5bcd61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#diff \n",
    "\n",
    "snowball_stem.stem(\"fairly\"),snowball_stem.stem(\"sportingly\")\n",
    "\n",
    "# we get good output, better than portal stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acba1a-8fc5-429e-9100-1e5ef2a2c064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
